{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import generator as g\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from utils import plots\n",
    "import matplotlib as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de Limiares\n",
    "\n",
    "Podem ser utilizada na predição caso os dados não sejam normalizados para saída do problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "same = lambda x: x\n",
    "# tupla(x,limit)\n",
    "threshold = lambda x: np.where(x[0]>x[1], 1, 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de Ativação\n",
    "\n",
    "Todas as funções de ativação possíveis para rede neural deste notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid: saída entre [0,1]\n",
    "def sigmoid(x, derivative=False):\n",
    "    if derivative:\n",
    "        y = sigmoid(x)\n",
    "        return y*(1 - y)\n",
    "    return 1.0/(1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tangente Hiperbólica: saída entre [-1,1]\n",
    "def tanh(x, derivative=False):\n",
    "    if derivative:\n",
    "        y = tanh(x)\n",
    "        return 1 - y**2\n",
    "    return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retificadora (Relu): saída 0 caso entrada seja negativa e maior que 1 caso contrário\n",
    "def relu(x, derivative=False):\n",
    "    if derivative:\n",
    "        return np.where(x <= 0, 0, 1)\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degrau: saída 0 se menor que 0 e saída 1 caso contrário\n",
    "def step(x,derivative=False):\n",
    "    if derivative:\n",
    "        return np.where(x>0,1,1)\n",
    "    return np.where(x>0,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x, derivative=False):\n",
    "    return np.ones_like(x) if derivative else x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, y_oh=None, derivative=False):\n",
    "    if derivative: \n",
    "        y_pred = softmax(x)\n",
    "        y_correct = np.argmax(y_oh, axis=1)\n",
    "        pk = y_pred[range(y_pred.shape[0]), y_correct]\n",
    "        y_pred[range(y_pred.shape[0]), y_correct] = pk*(1.0 - pk)\n",
    "        return y_pred\n",
    "    exp = np.exp(x)\n",
    "    return exp/np.sum(exp, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_log_likelihood(y_oh, y_pred, derivative=False):\n",
    "    y_correct = np.argmax(y_oh, axis=1)\n",
    "    pk = y_pred[range(y_pred.shape[0]), y_correct]\n",
    "    if derivative:\n",
    "        y_pred[range(y_pred.shape[0]), y_correct] = (-1.0/pk)\n",
    "        return y_pred\n",
    "    return np.mean(-np.log(pk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de custo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y, y_pred, derivative=False):\n",
    "    if derivative:\n",
    "        return -(y - y_pred)\n",
    "    return np.mean((y - y_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_cross_entropy(y, y_pred, derivative=False):\n",
    "    if derivative:\n",
    "        return -(y - y_pred)\n",
    "    return -np.mean(y*np.log(y_pred) + (1-y)*np.log(1-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_neg_log_likelihood(y_oh, y_pred, derivative=False):\n",
    "    y_softmax = softmax(y_pred)\n",
    "    y_correct = np.argmax(y_oh, axis=1)\n",
    "    pk = y_softmax[range(y_softmax.shape[0]), y_correct]\n",
    "    if derivative:\n",
    "        return -(y_oh - y_softmax)/y_oh.shape[0]\n",
    "    return np.mean(-np.log(pk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) A representação de uma determinada mensagem digital ternária, isto é formada por três bits,\n",
    "forma um cubo cujos vértices correspondem a mesma representação digital. Supondo que ao\n",
    "transmitirmos esta mensagem a mesma possa ser contaminada por ruído formado em torno de\n",
    "cada vértice uma nuvem esférica de valores aleatórios com raio máximo é 0.1. Formule este\n",
    "problema como um problema de classificação de padrões e treine uma rede de Perceptron de\n",
    "Rosenblatt (Perceptron de camada única) para atuar como classificador/decodificador. Para\n",
    "solução do problema defina antes um conjunto de treinamento e um conjunto de validação.\n",
    "Dica: O problema pode ser formulado como um problema de classificação de 8 padrões\n",
    "diferentes, sendo que cada padrão representa um vértice do cubo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 3) (6000, 3) (24000, 8) (6000, 8)\n"
     ]
    }
   ],
   "source": [
    "# entradas\n",
    "x,y = g.data_1A1(30000,dtype='train')\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=6000, stratify=y, random_state=42)\n",
    "print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneLayer:\n",
    "    def __init__(self):\n",
    "        self.learning_rate = 0.02\n",
    "        self.w = np.random.random((8, 3))-0.5\n",
    "        self.b = np.zeros(8)\n",
    "\n",
    "    def forward(self, x_i):\n",
    "        y = np.dot(x_i, self.w.T) + self.b\n",
    "        return step(y)\n",
    "\n",
    "    def fit(self, x,y, epochs=100):\n",
    "        for e in range(epochs):\n",
    "             for x_i, y_i in zip(x,y):\n",
    "                x_i =  x_i.reshape(1, x.shape[1])\n",
    "                y_pred = self.forward(x_i)\n",
    "                error = y_i-y_pred\n",
    "                self.w = self.w + self.learning_rate*np.dot(error.T, x_i)\n",
    "                self.b = self.b + self.learning_rate*error[0]\n",
    "\n",
    "    def predict(self, x_val):\n",
    "        y_pred = []\n",
    "        for x in x_val:\n",
    "            x_i =  x.reshape(1, x_val.shape[1])\n",
    "            y_pred.append(self.forward(x_i))\n",
    "        return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: [[-0.25954883 -0.0036783  -0.27039416]\n",
      " [-0.25842308 -0.22443609  0.01012454]\n",
      " [-0.24351396  0.02257984 -0.02098974]\n",
      " [-0.35233733  0.16070935  0.18993595]\n",
      " [ 0.00967415 -0.04194115 -0.11428844]\n",
      " [ 0.04227542 -0.08606846  0.04075522]\n",
      " [ 0.03359623  0.02236152 -0.42323663]\n",
      " [ 0.04020493  0.18113023  0.045466  ]]\n",
      "b: [  6.93889390e-18  -6.93889390e-18  -2.00000000e-02  -2.20000000e-01\n",
      "  -6.93889390e-18  -8.00000000e-02  -4.00000000e-02  -2.60000000e-01]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 48000 into shape (0,8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-ba23bda33b15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'w:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-132-9921fa785eb7>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x_val)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 48000 into shape (0,8)"
     ]
    }
   ],
   "source": [
    "one = OneLayer()\n",
    "one.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "print('w:', one.w)\n",
    "print('b:', one.b)\n",
    "pred = one.predict(x_val)\n",
    "\n",
    "for a,b in zip(pred,y_val):\n",
    "    print(a,b.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, input_dim, output_dim, activation=step, use_bias=True):\n",
    "        self.input = None\n",
    "        self.weights = np.random.randn(output_dim, input_dim)\n",
    "        self.bias = np.random.randn(1, output_dim)\n",
    "        self.activation = activation\n",
    "        self._activ_inp, self._activ_out = None, None\n",
    "        self.input_dim = input_dim\n",
    "        self.use_bias = use_bias\n",
    "        self.dweights, self.dbias = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, cost_func=mse, learning_rate=0.02):\n",
    "        self._layers = []\n",
    "        self.cost_func = cost_func\n",
    "        self._learning_rate = learning_rate\n",
    "    \n",
    "    def __backpropagation(self, y,y_pred):\n",
    "        last_delta = self.cost_func(y, y_pred, derivative=True)\n",
    "        for layer in reversed(self._layers):\n",
    "            dactivation = layer.activation(layer._activ_inp, derivative=True)*last_delta\n",
    "            last_delta = np.dot(dactivation, layer.weights)\n",
    "            layer.dweights = np.dot(dactivation.T, layer.input)\n",
    "            layer.dbias = 1.0*dactivation.sum(axis=0, keepdims=True)\n",
    "        \n",
    "        for layer in reversed(self._layers):\n",
    "            layer.weights = layer.weights - self._learning_rate*layer.dweights\n",
    "            layer.biases = layer.bias - self._learning_rate*layer.dbias\n",
    "    \n",
    "    def __forward(self, x):\n",
    "        self._layers[0].input = x\n",
    "        for current_layer, next_layer in zip(self._layers, self._layers[1:] + [Layer(0,0)]):\n",
    "            y = np.dot(current_layer.input, current_layer.weights.T) + current_layer.bias\n",
    "            current_layer._activ_inp = y\n",
    "            current_layer._activ_out = next_layer.input = current_layer.activation(y)\n",
    "        return self._layers[-1]._activ_out\n",
    "\n",
    "    def add(self, layer):\n",
    "        self._layers.append(layer)\n",
    "    \n",
    "    def evaluate(self,y_pred, y, func=same, dtype=int):\n",
    "        score = 0\n",
    "        total = 100.0/y.shape[0]\n",
    "        # mesmo tipo de saida\n",
    "        y_pred = y_pred.astype(dtype)\n",
    "        y = y.astype(dtype)\n",
    "\n",
    "        for y_i, y_pred_i in zip(y,y_pred):\n",
    "            y_pred_i = func(y_pred_i)\n",
    "            if np.array_equal(y_i,y_pred_i):\n",
    "                score+=1\n",
    "        return score*total\n",
    "\n",
    "    def fit(self, X=None, Y=None, epochs=1, batch_size=None, verbose=False):\n",
    "        batch_size = X.shape[0] if batch_size is None else batch_size\n",
    "        n_batches = X.shape[0] // batch_size\n",
    "        \n",
    "        for step in range(epochs+1):\n",
    "            # treino cada batch\n",
    "            for batch in range(n_batches):\n",
    "                offset = batch_size * batch\n",
    "                # conjunto de treinamento por batch\n",
    "                X_batch, Y_batch = X[offset:offset+batch_size], Y[offset:offset+batch_size]\n",
    "\n",
    "                y_pred = self.__forward(X)\n",
    "                self.__backpropagation(Y, y_pred)\n",
    "            \n",
    "    def get_learning_rate(self):\n",
    "        return self._learning_rate\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self._layers[-1].weights, self._layers[-1].bias\n",
    "\n",
    "    def predict(self, X, verbose=False):\n",
    "        return self.__forward(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Questão "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 3) (6000, 3) (24000, 8) (6000, 8)\n"
     ]
    }
   ],
   "source": [
    "x,y = g.data_1A1(30000,dtype='train')\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=6000, stratify=y, random_state=42)\n",
    "print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: [[ 184.97874287 -185.44848326  -55.87451029 -113.70068089    7.67357322\n",
      "    66.09479742 -297.58445231 -181.40371621]\n",
      " [   5.10528284  210.99952097  -69.42477597  -12.17347771 -173.1538998\n",
      "  -226.48817866 -219.21580945  -20.54127108]\n",
      " [   1.16916264 -117.11079734 -237.49222091  131.05042728   -8.55011415\n",
      "  -119.61790559  -55.45485623 -180.13989624]\n",
      " [  40.146012     31.0696378    14.92989974   -4.92347076 -132.34769726\n",
      "  -245.09945357  -54.18427072 -243.96694029]\n",
      " [-181.62460823  -56.8198296  -237.88496285 -179.73244554    7.2124858\n",
      "    12.38664317 -237.72191894   12.17559083]\n",
      " [-121.16944497  -16.80277194   27.80871974 -203.53244089 -138.17817584\n",
      "    38.4194186  -242.92218511  -46.22731046]\n",
      " [-238.47655114 -299.40765597 -240.38724815 -110.5533294   -44.75276054\n",
      "    67.72889745   90.01526576 -118.04275964]\n",
      " [-122.39217433 -181.16926031   65.28273439 -170.82330076 -188.14713026\n",
      "  -124.34209529   68.36005456   -9.37824742]]\n",
      "b: [[-2.62929008 -0.71099705 -0.21755788 -1.51458177 -0.76637893  0.12508161\n",
      "   1.68587036 -0.37030758]]\n",
      "Accurancy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "D_in, D_out = x_train.shape[1], y_train.shape[1]\n",
    "model = NeuralNetwork()\n",
    "model.add(Layer(input_dim=D_in, output_dim=D_out, activation=step))\n",
    "model.add(Layer(input_dim=8, output_dim=8, activation=step))\n",
    "model.fit(x_train, y_train, batch_size=2000, epochs=500, verbose=False)\n",
    "\n",
    "w,b = model.get_weights()\n",
    "y_pred = model.predict(x_val, verbose=False)\n",
    "accurancy = model.evaluate(y_pred, y_val, func=same)\n",
    "\n",
    "print('w:', w)\n",
    "print('b:', b)\n",
    "print('Accurancy: {0:.1f}%'.format(accurancy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Questão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2) (4, 1)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([0, 1, 1, 0]).reshape(-1, 1)\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predições:\n",
      "[[ 0.14474569]\n",
      " [ 0.86964007]\n",
      " [ 0.90186175]\n",
      " [ 0.06859569]]\n",
      "Accurancy: 100.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAFpCAYAAACfyu4TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25054dead68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D_in, D_out = x.shape[1], y.shape[1]\n",
    "model = NeuralNetwork(cost_func=, learning_rate=1.0)\n",
    "model.add(Layer(input_dim=D_in, output_dim=2, activation=sigmoid))\n",
    "model.add(Layer(input_dim=2, output_dim=D_out, activation=sigmoid))\n",
    "\n",
    "model.fit(x, y, epochs=2000)\n",
    "y_pred = model.predict(x)\n",
    "print('Predições:', y_pred, sep='\\n')\n",
    "print('Accurancy: {0:.1f}%'.format(accurancy))\n",
    "plots.plot_data_and_predictions_3d_in_2d(x, y, is_binary=True, nn=model, threshold=0.5, cmap='bwr')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
